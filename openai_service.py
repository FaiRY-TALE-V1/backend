import openai
import os
import uuid
import time
import json
from typing import Dict, Any
from config import settings
from models import (
    StoryRequest, Story, StoryScene, CompleteStoryResponse
)
from typing import Tuple

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = openai.OpenAI(api_key=settings.OPENAI_API_KEY)

class OpenAIStoryService:
    """OpenAI ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•œ ì™„ì „í•œ ë™í™” ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        pass
    
    async def analyze_child_photo(self, photo_base64: str, child_name: str, child_age: int, child_gender: str) -> str:
        """ì—…ë¡œë“œëœ ì•„ì´ ì‚¬ì§„ì„ ë¶„ì„í•˜ì—¬ ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            print(f"ğŸ“¸ {child_name}ì˜ ì‚¬ì§„ ë¶„ì„ ì¤‘...")
            
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": f"""As an art director creating a children's book character, please analyze the visual characteristics in this illustration reference for creating a consistent animated character design.

Please provide a character design description in English that includes:
- Face shape and proportions
- Eye style and expression  
- Hair design and color
- Overall appearance style
- Clothing or outfit suggestions

This is for creating a consistent illustrated character across multiple scenes in an educational children's storybook. The character should be age-appropriate for a {child_age}-year-old child.

Format example: "round friendly face, large expressive eyes, neat hair style, casual children's clothing, warm and approachable appearance"

This analysis will be used purely for artistic character consistency in children's educational content."""
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": photo_base64
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500,
                temperature=0.3  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature
            )
            
            facial_features = response.choices[0].message.content
            print(f"âœ… ì–¼êµ´ íŠ¹ì§• ë¶„ì„ ì™„ë£Œ: {facial_features[:100]}...")
            return facial_features
            
        except Exception as e:
            print(f"âŒ ì‚¬ì§„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            # ê¸°ë³¸ê°’ ë°˜í™˜
            return f"Korean {child_gender}, {child_age} years old, round face, big expressive eyes, short black hair, fair skin, cheerful expression"

    def generate_detailed_character_description(self, child_name: str, child_age: int, child_gender: str, facial_features: str = None) -> str:
        """ìƒì„¸í•œ ìºë¦­í„° ë””ìŠ¤í¬ë¦½ì…˜ ìƒì„± (DALL-E 3ìš©)"""
        if facial_features and "sorry" not in facial_features.lower():
            # ì‚¬ì§„ ë¶„ì„ì´ ì„±ê³µí•œ ê²½ìš°
            base_features = facial_features
        else:
            # ê¸°ë³¸ í•œêµ­ ì•„ì´ íŠ¹ì§• ì‚¬ìš©
            if child_gender.lower() in ['ì—¬ì', 'female', 'girl']:
                base_features = "round face, big expressive dark eyes, straight black hair with bangs, fair skin tone, small nose, gentle smile, innocent expression"
            else:
                base_features = "round face, big expressive dark eyes, short black hair, fair skin tone, small nose, cheerful smile, bright expression"
        
        return f"Korean {child_age}-year-old {child_gender}, {base_features}, wearing simple casual children's clothes"
    
    def enhance_prompt_for_consistency(self, base_prompt: str, character_description: str, scene_number: int) -> str:
        """ìºë¦­í„° ì¼ê´€ì„±ì„ ìœ„í•œ ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        consistency_keywords = [
            "CONSISTENT CHARACTER:",
            "SAME CHILD IN ALL SCENES:",
            "IDENTICAL APPEARANCE:",
            "WATERCOLOR CHILDREN'S BOOK STYLE:",
            "SOFT PASTEL COLORS:",
            "2D ILLUSTRATION:",
        ]
        
        enhanced_prompt = f"""
{consistency_keywords[scene_number % len(consistency_keywords)]} {character_description}

SCENE DESCRIPTION: {base_prompt}

STYLE REQUIREMENTS: 
- Soft watercolor children's book illustration
- Consistent 2D art style (not 3D)
- Warm pastel color palette (coral pink, soft blue, cream yellow, light green)
- Child-friendly, gentle lighting
- The main character must look EXACTLY the same as in previous scenes
- Same facial features, hair style, clothing throughout the story
"""
        
        return enhanced_prompt.strip()

    def generate_character_style_guide(self, child_name: str, child_age: int, child_gender: str, facial_features: str = None) -> str:
        """ìºë¦­í„° ì¼ê´€ì„±ì„ ìœ„í•œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ìƒì„± (ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ í¬í•¨)"""
        if facial_features:
            character_description = facial_features
        else:
            character_description = f"Korean {child_gender}, {child_age} years old, round face, big expressive eyes, short black hair, fair skin"
            
        return f"""
CONSISTENT CHARACTER STYLE GUIDE for {child_name}:
- Main character: {child_name}, {child_age} years old Korean {child_gender}
- Character physical features: {character_description}
- Art style: Soft watercolor children's book illustration, consistent across all scenes
- Drawing style: Consistent 2D illustration style, not 3D, similar to classic children's storybooks  
- Character should look EXACTLY the same in every scene with identical facial features, hair, and appearance
- Color palette: Warm, soft pastels that complement the child's features
- Background style: Simple, clean, child-friendly environments
- Lighting: Soft, warm natural lighting throughout all scenes
- Clothing: Simple, age-appropriate casual clothes that stay consistent
"""

    def generate_story_prompt(self, child_name: str, child_age: int, child_gender: str, theme: str, facial_features: str = None) -> str:
        """í…Œë§ˆë³„ ë™í™” ìƒì„± í”„ë¡¬í”„íŠ¸ ì‘ì„± (ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ í¬í•¨)"""
        
        theme_guidelines = {
            "ì‹ìŠµê´€ ê°œì„ ": {
                "context": "ê±´ê°•í•œ ì‹ìŠµê´€ì˜ ì¤‘ìš”ì„±ì„ ë°°ìš°ëŠ”",
                "key_lessons": ["ë‹¤ì–‘í•œ ìŒì‹ ê³¨ê³ ë£¨ ë¨¹ê¸°", "í¸ì‹í•˜ì§€ ì•Šê¸°", "ê±´ê°•í•œ ê°„ì‹ ì„ íƒ"],
                "characters": "ì˜ì–‘ì†Œ ìš”ì •ë“¤, ê±´ê°•í•œ ìŒì‹ ì¹œêµ¬ë“¤",
                "setting": "ë§ˆë²•ì˜ ìŒì‹ ë‚˜ë¼ë‚˜ ê±´ê°• ë ˆìŠ¤í† ë‘"
            },
            "êµìš°ê´€ê³„": {
                "context": "ì¹œêµ¬ë“¤ê³¼ì˜ ì˜¬ë°”ë¥¸ ê´€ê³„ í˜•ì„±ì„ ë°°ìš°ëŠ”",
                "key_lessons": ["ë°°ë ¤ì™€ ë‚˜ëˆ”", "í˜‘ë ¥ì˜ ì¤‘ìš”ì„±", "ë‹¤ë¦„ ì¸ì •í•˜ê¸°"],
                "characters": "ë‹¤ì–‘í•œ ì„±ê²©ì˜ ì¹œêµ¬ë“¤, ì§€í˜œë¡œìš´ ì„ ìƒë‹˜",
                "setting": "í•™êµ, ë†€ì´í„°, ì¹œêµ¬ë“¤ê³¼ì˜ ëª¨í—˜"
            },
            "ì•ˆì „ìŠµê´€": {
                "context": "ì¼ìƒìƒí™œì—ì„œì˜ ì•ˆì „ ìˆ˜ì¹™ì„ ë°°ìš°ëŠ”",
                "key_lessons": ["êµí†µì•ˆì „ ì§€í‚¤ê¸°", "í™”ì¬ ì˜ˆë°©", "ë†€ì´ ì•ˆì „"],
                "characters": "ì•ˆì „ ìˆ˜í˜¸ì²œì‚¬, ê²½ì°°ê´€, ì†Œë°©ê´€",
                "setting": "ì§‘, í•™êµ, ê¸¸ê±°ë¦¬, ë†€ì´í„°"
            },
            "ê²½ì œê´€ë…": {
                "context": "ëˆì˜ ì†Œì¤‘í•¨ê³¼ ì˜¬ë°”ë¥¸ ì†Œë¹„ ìŠµê´€ì„ ë°°ìš°ëŠ”",
                "key_lessons": ["ì €ì¶•ì˜ ì¤‘ìš”ì„±", "í•„ìš”ì™€ ìš•êµ¬ êµ¬ë¶„", "ê³„íšì  ì†Œë¹„"],
                "characters": "ë¼ì§€ ì €ê¸ˆí†µ, ì€í–‰ì›, í˜„ëª…í•œ í• ë¨¸ë‹ˆ",
                "setting": "ìƒì , ì€í–‰, ì§‘ì•ˆì—ì„œì˜ ìš©ëˆ ê´€ë¦¬"
            },
            "ê°ì •í‘œí˜„": {
                "context": "ìì‹ ì˜ ê°ì •ì„ ì˜¬ë°”ë¥´ê²Œ í‘œí˜„í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ëŠ”",
                "key_lessons": ["ê°ì • ì¸ì‹í•˜ê¸°", "ê±´ì „í•œ í‘œí˜„ ë°©ë²•", "íƒ€ì¸ ê°ì • ì´í•´"],
                "characters": "ê°ì • ìš”ì •ë“¤, ì´í•´ì‹¬ ë§ì€ ê°€ì¡±",
                "setting": "ê°€ì •, ê°ì •ì˜ ì •ì›, ë§ˆìŒì˜ ì„¸ê³„"
            }
        }
        
        current_theme = theme_guidelines.get(theme, theme_guidelines["êµìš°ê´€ê³„"])
        style_guide = self.generate_character_style_guide(child_name, child_age, child_gender, facial_features)
        
        # ê°ì •í‘œí˜„ í…Œë§ˆ ì „ìš© ìŠ¤í† ë¦¬ ë‹¤ì–‘ì„± ìš”ì†Œ
        import random
        emotion_themes = [
            "ê¸°ì¨ê³¼ ìŠ¬í””ì„ ê· í˜•ìˆê²Œ í‘œí˜„í•˜ëŠ”", "í™”ê°€ ë‚  ë•Œ ì˜¬ë°”ë¥´ê²Œ ëŒ€ì²˜í•˜ëŠ”", 
            "ë¬´ì„œì›€ì„ ê·¹ë³µí•˜ëŠ”", "ë¶€ë„ëŸ¬ì›€ì„ ì´ê²¨ë‚´ëŠ”", "ì‹¤ë§ê°ì„ ë‹¤ë£¨ëŠ”", "ì§ˆíˆ¬ì‹¬ì„ ì¡°ì ˆí•˜ëŠ”"
        ]
        random_emotion = random.choice(emotion_themes)
        
        emotion_scenarios = [
            "ê°ì • ìš”ì •ë“¤ì„ ë§Œë‚˜ëŠ”", "ë§ˆìŒì˜ ì •ì›ì„ ê°€ê¾¸ëŠ”", "ê°ì • ìƒ‰ê¹”ì„ ì°¾ëŠ”",
            "ë§ˆìŒì˜ ë‚ ì”¨ë¥¼ ë°”ê¾¸ëŠ”", "ê°ì • ë™ë¬¼ ì¹œêµ¬ë“¤ê³¼ ë†€ì´í•˜ëŠ”", "ë§ˆìŒì˜ ë³´ì„ì„ ì°¾ëŠ”"
        ]
        emotion_scenario = random.choice(emotion_scenarios)
        
        prompt = f"""
ë‹¹ì‹ ì€ ì„¸ê³„ì ìœ¼ë¡œ ìœ ëª…í•œ ì•„ë™ë¬¸í•™ ì‘ê°€ì…ë‹ˆë‹¤. ê°ì •í‘œí˜„ì„ ì£¼ì œë¡œ í•œ ê°ë™ì ì´ê³  êµìœ¡ì ì¸ ë™í™”ë¥¼ ì°½ì‘í•´ì£¼ì„¸ìš”.

ğŸ¨ ê°ì •í‘œí˜„ ìŠ¤í† ë¦¬: {random_emotion} ë°©ë²•ì„ ë°°ìš°ëŠ” {emotion_scenario} ì´ì•¼ê¸°ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
ğŸ“– ë§¤ë²ˆ ë‹¤ë¥¸ ì œëª©ê³¼ ë‚´ìš©ìœ¼ë¡œ ì°½ì‘í•´ì£¼ì„¸ìš” (í…œí”Œë¦¿ ì‚¬ìš© ê¸ˆì§€).

ğŸ“š ì‘í’ˆ ì •ë³´:
- ì£¼ì¸ê³µ: {child_name} ({child_age}ì„¸)
- êµìœ¡ í…Œë§ˆ: {theme}
- ëª©í‘œ: {current_theme['context']} ë™í™”

ğŸ¯ í•µì‹¬ êµí›ˆ: {', '.join(current_theme['key_lessons'])}

ğŸŒŸ ì°½ì‘ ê°€ì´ë“œë¼ì¸:
1. ì—°ë ¹ ì í•©ì„±: {child_age}ì„¸ ì•„ì´ì˜ ì–¸ì–´ ë°œë‹¬ê³¼ ì´í•´ë ¥ì— ë§ì¶˜ ì–´íœ˜ì™€ ë¬¸ì¥ êµ¬ì¡°
2. ëª°ì…ê°: {child_name}ì´ ì£¼ì¸ê³µì´ ë˜ì–´ ì§ì ‘ ê²½í—˜í•˜ëŠ” ë“¯í•œ ìƒìƒí•œ ë¬˜ì‚¬
3. êµìœ¡ì  ê°€ì¹˜: {theme}ì˜ ì¤‘ìš”ì„±ì„ ê°•ìš”í•˜ì§€ ì•Šê³  ìì—°ìŠ¤ëŸ½ê²Œ ê¹¨ë‹¬ì„ ìˆ˜ ìˆëŠ” ìŠ¤í† ë¦¬
4. ê°ì •ì  ì—°ê²°: ì•„ì´ê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ìƒí™©ê³¼ ê°ì • ë³€í™”
5. ê¸ì •ì  ê²°ë§: ì„±ì¥ê³¼ ë°°ì›€ì„ í†µí•œ í¬ë§ì ì´ê³  ë”°ëœ»í•œ ë§ˆë¬´ë¦¬

ğŸ­ ë“±ì¥ì¸ë¬¼ í™œìš©: {current_theme['characters']}
ğŸï¸ ë°°ê²½ ì„¤ì •: {current_theme['setting']}

ğŸ“– êµ¬ì„± ìš”êµ¬ì‚¬í•­:
- ì´ 6ê°œ ì¥ë©´ìœ¼ë¡œ êµ¬ì„±
- ê° ì¥ë©´: 2-3ë¬¸ì¥ (ì•„ì´ê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ê¸¸ì´)
- ì¥ë©´ë³„ ëª…í™•í•œ ì „ê°œì™€ êµí›ˆ ì—°ê²°
- DALL-E 3ìš© ìƒì„¸í•œ ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í¬í•¨

ì‘ë‹µ í˜•ì‹ (JSON):
{{
    "title": "ë§¤ë ¥ì ì´ê³  êµìœ¡ì ì¸ ë™í™” ì œëª©",
    "scenes": [
        {{
            "scene_number": 1,
            "text": "ìƒìƒí•˜ê³  ëª°ì…ê° ìˆëŠ” ì¥ë©´ ì„œìˆ ",
            "image_prompt": "CONSISTENT STYLE: Soft watercolor children's book illustration. {child_name}, {child_age}-year-old Korean {child_gender} with [KEEP_CONSISTENT_CHARACTER_FEATURES]. [Specific scene description]. Warm pastel colors, soft natural lighting, 2D illustration style, child-friendly background. Character must look identical to previous scenes."
        }}
    ]
}}
"""
        return prompt
    
    async def generate_story_with_gpt4o_mini(self, request: StoryRequest, facial_features: str = None) -> Dict[str, Any]:
        """GPT-4o-minië¥¼ ì‚¬ìš©í•œ ìŠ¤í† ë¦¬ ìƒì„± (ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ í¬í•¨)"""
        try:
            print(f"ğŸ“ GPT-4o-minië¡œ ìŠ¤í† ë¦¬ ìƒì„± ì¤‘...")
            
            prompt = self.generate_story_prompt(
                request.child_profile.name,
                request.child_profile.age,
                request.child_profile.gender,
                request.theme,
                facial_features
            )
            
            response = client.chat.completions.create(
                model=settings.STORY_MODEL,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ ì„¸ê³„ì ìœ¼ë¡œ ìœ ëª…í•œ ì•„ë™ë¬¸í•™ ì‘ê°€ì…ë‹ˆë‹¤. êµìœ¡ì  ê°€ì¹˜ì™€ ì¬ë¯¸ë¥¼ ëª¨ë‘ ê°–ì¶˜ ê°ë™ì ì¸ ë™í™”ë¥¼ ì°½ì‘í•˜ì„¸ìš”. ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ í•´ì£¼ì„¸ìš”."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=2000
            )
            
            story_text = response.choices[0].message.content
            print(f"GPT-4o-mini ì‘ë‹µ: {story_text[:200]}...")
            
            # JSON íŒŒì‹±
            try:
                json_start = story_text.find('{')
                json_end = story_text.rfind('}') + 1
                if json_start != -1 and json_end != -1:
                    json_text = story_text[json_start:json_end]
                    story_data = json.loads(json_text)
                    print(f"âœ… ìŠ¤í† ë¦¬ ìƒì„± ì™„ë£Œ: {story_data.get('title', 'ì œëª© ì—†ìŒ')}")
                    return story_data
                else:
                    raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            except Exception as e:
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
                # ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
                return {
                    "title": f"{request.child_profile.name}ì˜ {request.theme} ì´ì•¼ê¸°",
                    "scenes": [
                        {
                            "scene_number": 1,
                            "text": f"{request.child_profile.name}ëŠ” {request.theme}ì— ëŒ€í•´ ë°°ìš°ê¸° ì‹œì‘í–ˆì–´ìš”.",
                            "image_prompt": f"Children's book illustration of a Korean child learning about {request.theme}"
                        }
                    ]
                }
                
        except Exception as e:
            print(f"âŒ GPT-4o-mini ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise e
    
    async def generate_image_with_dalle3(self, image_prompt: str, scene_number: int, reference_gen_id: str = None) -> Tuple[str, str]:
        """DALL-E 3ë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒì„± (gen_id ê¸°ë°˜ ì¼ê´€ì„±)"""
        try:
            print(f"ğŸ¨ DALL-E 3ë¡œ ì¥ë©´ {scene_number} ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            
            # gen_idê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•˜ì—¬ ìºë¦­í„° ì¼ê´€ì„± ìœ ì§€
            if reference_gen_id:
                image_prompt = f"[Reference generation ID for character consistency: {reference_gen_id}] {image_prompt}"
                print(f"ğŸ¯ ìºë¦­í„° ì¼ê´€ì„±ì„ ìœ„í•œ Gen ID ì°¸ì¡°: {reference_gen_id}")
            
            response = client.images.generate(
                model="dall-e-3",
                prompt=image_prompt,
                size="1024x1024",  # DALL-E 3 ìµœì†Œ ì§€ì› í•´ìƒë„
                quality="standard",  # í’ˆì§ˆ ìœ ì§€
                n=1
            )
            
            image_url = response.data[0].url
            
            # gen_id ì¶”ì¶œ (DALL-E 3 ì‘ë‹µì—ì„œ)
            gen_id = None
            if hasattr(response.data[0], 'revised_prompt'):
                # ì‹¤ì œ API ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”
                gen_id = getattr(response.data[0], 'gen_id', None) or f"gen_{scene_number}_{hash(image_prompt) % 10000}"
            else:
                # gen_idê°€ ì—†ìœ¼ë©´ ì„ì‹œë¡œ ìƒì„±
                gen_id = f"gen_{scene_number}_{hash(image_prompt) % 10000}"
            
            print(f"âœ… ì¥ë©´ {scene_number} ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ, Gen ID: {gen_id}")
            return image_url, gen_id
            
        except Exception as e:
            print(f"âŒ DALL-E 3 ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨ì‹œ í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ë°˜í™˜
            placeholder_url = f"https://picsum.photos/1024/1024?random={scene_number}&blur=1"
            return placeholder_url, None
    
    async def generate_scene_with_reference(self, reference_image_url: str, scene_prompt: str, scene_number: int) -> str:
        """Scene 1ì„ ì°¸ì¡°í•˜ì—¬ ë‹¤ë¥¸ ì¥ë©´ë“¤ì„ images.edit APIë¡œ ìƒì„±"""
        try:
            print(f"ğŸ¨ ì¥ë©´ {scene_number} ì´ë¯¸ì§€ ìƒì„± ì¤‘ (ì°¸ì¡° ì´ë¯¸ì§€ ê¸°ë°˜)...")
            
            # ì°¸ì¡° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° PNG ë³€í™˜
            import requests
            from PIL import Image
            import io
            
            response = requests.get(reference_image_url)
            if response.status_code != 200:
                raise Exception(f"ì°¸ì¡° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {reference_image_url}")
            
            # PILë¡œ ì´ë¯¸ì§€ë¥¼ PNGë¡œ ë³€í™˜
            image = Image.open(io.BytesIO(response.content))
            png_buffer = io.BytesIO()
            image.save(png_buffer, format='PNG')
            png_buffer.seek(0)
            
            # OpenAI images.edit API í˜¸ì¶œ (PNG íŒŒì¼ ê°ì²´ë¡œ ì „ë‹¬)
            edit_response = client.images.edit(
                image=png_buffer,
                prompt=f"""Transform this scene while keeping the SAME CHARACTER with identical appearance: {scene_prompt}

IMPORTANT: The main character must look exactly the same as in the reference image:
- Same face, eyes, hair, skin tone
- Same artistic style and proportions  
- Same clothing style
- Only change the background and scene setting
- Maintain soft watercolor children's book illustration style""",
                size="1024x1024"
            )
            
            edited_image_url = edit_response.data[0].url
            print(f"âœ… ì¥ë©´ {scene_number} ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ì°¸ì¡° ê¸°ë°˜)")
            return edited_image_url
            
        except Exception as e:
            print(f"âŒ ì¥ë©´ {scene_number} ì°¸ì¡° ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            print(f"ğŸ”„ DALL-E 3 ì§ì ‘ ìƒì„±ìœ¼ë¡œ ëŒ€ì²´...")
            # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ DALL-E 3ë¡œ ëŒ€ì²´
            return await self.generate_image_with_dalle3(scene_prompt, scene_number)
    
    async def generate_audio_with_tts1(self, text: str, scene_number: int, child_name: str) -> str:
        """OpenAI TTS-1ì„ ì‚¬ìš©í•œ ìŒì„± ìƒì„±"""
        try:
            print(f"ğŸ”Š TTS-1ë¡œ ì¥ë©´ {scene_number} ìŒì„± ìƒì„± ì¤‘...")
            
            response = client.audio.speech.create(
                model="tts-1",
                voice=settings.TTS_VOICE,  # ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ëª©ì†Œë¦¬
                input=text
            )
            
            # ìŒì„± íŒŒì¼ ì €ì¥
            audio_filename = f"scene_{scene_number}_{child_name}_{int(time.time())}.mp3"
            audio_path = os.path.join(settings.AUDIO_DIR, audio_filename)
            
            with open(audio_path, "wb") as audio_file:
                audio_file.write(response.content)
            
            audio_url = f"/static/audio/{audio_filename}"
            print(f"âœ… ì¥ë©´ {scene_number} ìŒì„± ìƒì„± ì™„ë£Œ")
            return audio_url
            
        except Exception as e:
            print(f"âŒ TTS-1 ìŒì„± ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return ""  # ì‹¤íŒ¨ì‹œ ë¹ˆ ë¬¸ìì—´
    
    async def generate_complete_story(self, request: StoryRequest, facial_features: str = None) -> CompleteStoryResponse:
        """OpenAI ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•œ ì™„ì „í•œ ë™í™” ìƒì„± (ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ í¬í•¨)"""
        try:
            print(f"ğŸš€ OpenAI ì™„ì „ ë™í™” ìƒì„± ì‹œì‘: {request.child_profile.name}, í…Œë§ˆ: {request.theme}")
            if facial_features:
                print(f"ğŸ‘¶ ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ ì ìš©: {facial_features[:50]}...")
            
            # 1. GPT-4oë¡œ ìŠ¤í† ë¦¬ ìƒì„± (ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ í¬í•¨)
            story_data = await self.generate_story_with_gpt4o_mini(request, facial_features)
            
            # 2. ìƒì„¸í•œ ìºë¦­í„° ë””ìŠ¤í¬ë¦½ì…˜ ìƒì„±
            character_description = self.generate_detailed_character_description(
                request.child_profile.name, 
                request.child_profile.age, 
                request.child_profile.gender,
                facial_features
            )
            
            # 3. Gen ID ê¸°ë°˜ ìºë¦­í„° ì¼ê´€ì„± ìœ ì§€ ì‹œìŠ¤í…œ
            scenes = []
            reference_gen_id = None
            
            for i, scene_data in enumerate(story_data.get("scenes", [])[:6]):  # ìµœëŒ€ 6ê°œ ì¥ë©´
                scene_num = scene_data.get("scene_number", i + 1)
                scene_text = scene_data.get("text", "")
                base_image_prompt = scene_data.get("image_prompt", f"Children's book illustration, scene {scene_num}")
                
                # ì´ë¯¸ì§€ ìƒì„±
                if os.getenv("GENERATE_IMAGES", "false").lower() == "true":
                    enhanced_prompt = self.enhance_prompt_for_consistency(
                        base_image_prompt, 
                        character_description, 
                        scene_num
                    )
                    
                    # 2D ë™í™”ì±… ìŠ¤íƒ€ì¼ ê°•ì¡° (3D ë°©ì§€)
                    enhanced_prompt = f"2D flat illustration, watercolor children's book art style, NOT 3D: {enhanced_prompt}"
                    
                    if scene_num == 1:
                        # Scene 1: ê¸°ì¤€ ìºë¦­í„° ìƒì„± ë° gen_id ì €ì¥
                        image_url, reference_gen_id = await self.generate_image_with_dalle3(enhanced_prompt, scene_num)
                        print(f"ğŸ¯ Scene 1 ê¸°ì¤€ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ, Gen ID: {reference_gen_id}")
                    else:
                        # Scene 2-6: gen_id ì°¸ì¡°í•˜ì—¬ ìºë¦­í„° ì¼ê´€ì„± ìœ ì§€
                        image_url, _ = await self.generate_image_with_dalle3(enhanced_prompt, scene_num, reference_gen_id)
                        print(f"ğŸ¨ Scene {scene_num} ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (Gen ID ì°¸ì¡°)")
                    
                else:
                    # í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ì‚¬ìš© (ë¹„ìš© ì ˆì•½)
                    colors = ["8B5CF6", "EC4899", "F59E0B", "10B981", "3B82F6", "8B5A2B"]
                    color = colors[scene_num % len(colors)]
                    image_url = f"https://picsum.photos/1024/1024?random={scene_num}&blur=1"
                    print(f"ğŸ’° ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ì¥ë©´ {scene_num}ì— í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ì‚¬ìš©")
                
                # TTS-1ë¡œ ìŒì„± ìƒì„±
                audio_url = await self.generate_audio_with_tts1(scene_text, scene_num, request.child_profile.name)
                
                scene = StoryScene(
                    scene_number=scene_num,
                    text=scene_text,
                    image_url=image_url,
                    audio_url=audio_url
                )
                scenes.append(scene)
            
            # 3. ìµœì¢… ìŠ¤í† ë¦¬ êµ¬ì„±
            story = Story(
                title=story_data.get("title", f"{request.child_profile.name}ì˜ {request.theme} ì´ì•¼ê¸°"),
                scenes=scenes
            )
            
            # ìºë¦­í„° ì´ë¯¸ì§€ë„ ìƒì„± (ì„ íƒì )
            if os.getenv("GENERATE_IMAGES", "false").lower() == "true":
                character_prompt = f"2D flat illustration, watercolor children's book art style, NOT 3D: Children's book character illustration of {request.child_profile.name}, a {request.child_profile.age}-year-old Korean {request.child_profile.gender}, watercolor style, friendly and warm"
                character_image, _ = await self.generate_image_with_dalle3(character_prompt, 0)  # tupleì—ì„œ URLë§Œ ì¶”ì¶œ
            else:
                character_image = f"https://picsum.photos/1024/1024?random=character&blur=2"
            
            response = CompleteStoryResponse(
                story=story,
                character_image=character_image,
                total_scenes=len(scenes)
            )
            
            print(f"ğŸ‰ OpenAI ì™„ì „ ë™í™” ìƒì„± ì™„ë£Œ! '{story.title}' (ì´ {len(scenes)}ê°œ ì¥ë©´)")
            return response
            
        except Exception as e:
            print(f"âŒ OpenAI ì™„ì „ ë™í™” ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise e

# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
openai_story_service = OpenAIStoryService()
